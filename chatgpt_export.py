"""
ChatGPTå…¬å¼ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç›£è¦–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ãŸJSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•æ¤œçŸ¥ã—ã¦Evernoteã«åŒæœŸ

ä½¿ã„æ–¹:
1. ChatGPT â†’ Settings â†’ Data controls â†’ Export data
2. ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã•ã‚ŒãŸZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
3. æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€ã«é…ç½®ï¼ˆã¾ãŸã¯è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç›£è¦–ï¼‰
4. ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒè‡ªå‹•çš„ã«è§£æã—ã¦Evernoteã«åŒæœŸ
"""
import os
import json
import zipfile
import logging
from typing import List, Dict, Optional
from datetime import datetime
from pathlib import Path

logger = logging.getLogger(__name__)


class ChatGPTExportParser:
    """ChatGPTå…¬å¼ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«è§£æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, export_dir: str):
        """
        Args:
            export_dir: ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        self.export_dir = export_dir
        os.makedirs(export_dir, exist_ok=True)
        logger.info(f"ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç›£è¦–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {export_dir}")
    
    def find_export_files(self) -> List[str]:
        """
        ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆZIPï¼‰ã‚’æ¤œç´¢
        
        Returns:
            ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ãƒªã‚¹ãƒˆ
        """
        zip_files = []
        for file in os.listdir(self.export_dir):
            if file.endswith('.zip') and 'chatgpt' in file.lower():
                full_path = os.path.join(self.export_dir, file)
                zip_files.append(full_path)
        
        zip_files.sort(key=lambda x: os.path.getmtime(x), reverse=True)
        logger.info(f"æ¤œå‡ºã•ã‚ŒãŸã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: {len(zip_files)}å€‹")
        return zip_files
    
    def extract_zip(self, zip_path: str, extract_dir: Optional[str] = None) -> str:
        """
        ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’å±•é–‹
        
        Args:
            zip_path: ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            extract_dir: å±•é–‹å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆNoneã®å ´åˆã¯è‡ªå‹•ç”Ÿæˆï¼‰
        
        Returns:
            å±•é–‹å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹
        """
        if extract_dir is None:
            zip_name = os.path.basename(zip_path).replace('.zip', '')
            extract_dir = os.path.join(self.export_dir, f"extracted_{zip_name}")
        
        os.makedirs(extract_dir, exist_ok=True)
        
        logger.info(f"ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’å±•é–‹ä¸­: {zip_path}")
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(extract_dir)
        
        logger.info(f"å±•é–‹å®Œäº†: {extract_dir}")
        return extract_dir
    
    def parse_conversations_json(self, json_path: str) -> List[Dict]:
        """
        conversations.jsonã‚’è§£æ
        
        Args:
            json_path: JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        
        Returns:
            ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
        """
        logger.info(f"ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚’è§£æä¸­: {json_path}")
        
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            conversations = []
            
            # ChatGPTã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå½¢å¼ã®è§£æ
            # å½¢å¼ä¾‹: [{"id": "...", "title": "...", "create_time": ..., "mapping": {...}}]
            if isinstance(data, list):
                for conv in data:
                    parsed = self._parse_conversation(conv)
                    if parsed:
                        conversations.append(parsed)
            
            logger.info(f"è§£æå®Œäº†: {len(conversations)}ä»¶ã®ä¼šè©±")
            return conversations
        
        except Exception as e:
            logger.error(f"JSONè§£æã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def _parse_conversation(self, conv_data: Dict) -> Optional[Dict]:
        """
        å€‹åˆ¥ã®ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚’è§£æ
        
        Args:
            conv_data: ä¼šè©±ã®ç”Ÿãƒ‡ãƒ¼ã‚¿
        
        Returns:
            æ•´å½¢ã•ã‚ŒãŸä¼šè©±ãƒ‡ãƒ¼ã‚¿
        """
        try:
            conversation_id = conv_data.get('id', '')
            title = conv_data.get('title', 'Untitled')
            create_time = conv_data.get('create_time')
            update_time = conv_data.get('update_time')
            
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒãƒƒãƒ”ãƒ³ã‚°ã‹ã‚‰å®Ÿéš›ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æŠ½å‡º
            mapping = conv_data.get('mapping', {})
            messages = []
            
            for node_id, node in mapping.items():
                message = node.get('message')
                if message:
                    author_role = message.get('author', {}).get('role')
                    content = message.get('content', {})
                    
                    # ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æŠ½å‡º
                    if isinstance(content, dict):
                        parts = content.get('parts', [])
                        text = '\n'.join(str(part) for part in parts if part)
                    else:
                        text = str(content)
                    
                    if text:
                        messages.append({
                            'role': author_role,
                            'content': text,
                            'create_time': message.get('create_time')
                        })
            
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ™‚ç³»åˆ—ã§ã‚½ãƒ¼ãƒˆ
            messages.sort(key=lambda x: x.get('create_time', 0))
            
            return {
                'id': conversation_id,
                'title': title,
                'messages': messages,
                'create_time': create_time,
                'update_time': update_time
            }
        
        except Exception as e:
            logger.error(f"ä¼šè©±è§£æã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def process_export_file(self, zip_path: str) -> List[Dict]:
        """
        ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
        
        Args:
            zip_path: ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        
        Returns:
            å…¨ä¼šè©±ãƒ‡ãƒ¼ã‚¿
        """
        # ZIPã‚’å±•é–‹
        extract_dir = self.extract_zip(zip_path)
        
        # conversations.jsonã‚’æ¢ã™
        conversations_file = None
        for root, dirs, files in os.walk(extract_dir):
            for file in files:
                if file == 'conversations.json':
                    conversations_file = os.path.join(root, file)
                    break
            if conversations_file:
                break
        
        if not conversations_file:
            logger.error("conversations.jsonãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return []
        
        # ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚’è§£æ
        return self.parse_conversations_json(conversations_file)
    
    def format_for_evernote(self, conversation: Dict) -> Dict:
        """
        ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚’Evernoteç”¨ã«æ•´å½¢
        
        Args:
            conversation: ä¼šè©±ãƒ‡ãƒ¼ã‚¿
        
        Returns:
            Evernoteç”¨ã®æ•´å½¢ãƒ‡ãƒ¼ã‚¿
        """
        title = conversation['title']
        create_time = datetime.fromtimestamp(conversation['create_time']) if conversation['create_time'] else None
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ•´å½¢
        content_parts = []
        for msg in conversation['messages']:
            role = msg['role']
            role_label = "ğŸ‘¤ User" if role == "user" else "ğŸ¤– Assistant"
            content_parts.append(f"**{role_label}:**\n{msg['content']}\n")
        
        content = '\n---\n\n'.join(content_parts)
        
        return {
            'title': title,
            'content': content,
            'create_time': create_time,
            'conversation_id': conversation['id']
        }


def test_export_parser():
    """ãƒ†ã‚¹ãƒˆé–¢æ•°"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    # Windowsã®æ¨™æº–ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ«ãƒ€ã‚’ç›£è¦–
    downloads_dir = str(Path.home() / "Downloads")
    export_dir = os.path.join(downloads_dir, "ChatGPT_Exports")
    
    print("=" * 60)
    print("ChatGPTå…¬å¼ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆè§£æãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    print(f"\nç›£è¦–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {export_dir}")
    print("\nã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ‰‹é †:")
    print("1. https://chat.openai.com/")
    print("2. Settings â†’ Data controls â†’ Export data")
    print("3. ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸Šè¨˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®")
    print("=" * 60)
    
    parser = ChatGPTExportParser(export_dir)
    
    # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    export_files = parser.find_export_files()
    
    if not export_files:
        print("\nã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print(f"ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ {export_dir} ã«é…ç½®ã—ã¦ãã ã•ã„")
        return
    
    print(f"\næ¤œå‡ºã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«: {len(export_files)}å€‹")
    
    # æœ€æ–°ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
    latest_file = export_files[0]
    print(f"\nå‡¦ç†ä¸­: {os.path.basename(latest_file)}")
    
    conversations = parser.process_export_file(latest_file)
    print(f"\nâœ“ è§£æå®Œäº†: {len(conversations)}ä»¶ã®ä¼šè©±")
    
    # ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
    if conversations:
        print("\n=== æœ€åˆã®ä¼šè©±ã‚µãƒ³ãƒ—ãƒ« ===")
        sample = conversations[0]
        print(f"ã‚¿ã‚¤ãƒˆãƒ«: {sample['title']}")
        print(f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°: {len(sample['messages'])}")
        
        formatted = parser.format_for_evernote(sample)
        print(f"\nEvernoteç”¨ã‚¿ã‚¤ãƒˆãƒ«: {formatted['title']}")
        print(f"ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼:\n{formatted['content'][:300]}...")


if __name__ == "__main__":
    test_export_parser()
